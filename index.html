<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  

  <title>Deniz Engin</title>
  <meta name="description" content="Deniz Engin | Personal Website">
  <meta name="author" content="Deniz Engin">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Deniz Engin">
  <meta name="twitter:description" content="Deniz Engin | Personal Website">
  
  <meta name="twitter:creator" content="Deniz.Engin_">
  


  <meta property="og:type" content="article">
  <meta property="og:title" content="Deniz Engin">
  <meta property="og:description" content="Deniz Engin | Personal Website">
  
  <meta name="msapplication-TileColor" content="#ffc40d">
  
  <meta name="theme-color" content="#ffffff">
  
  <link rel="stylesheet" href="css/main.css?1589893399693513343">
  <link rel="canonical" href="http://localhost:4000">
  <link rel="alternate" type="application/rss+xml" title="Deniz Engin" href="feed.xml">
</head>


  <body>
    <span class="mobile btn-mobile-menu">
  <i class="icon icon-list btn-mobile-menu__icon"></i>
  <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
</span>

<header class="panel-cover panel-cover--collapsed left-bar" style="background-image: url(images/cover.jpg); ">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <a href="" title="link to home of Deniz Engin">
          <img src="images/profile.jpg" class="user-image" alt="My Profile Photo">
          <h1 class="panel-cover__title panel-title">Deniz Engin</h1>
       <!--  </a>
        <hr class="panel-cover__divider">
        <p class="panel-cover__description">Deniz Engin | Personal Website</p>
    -->
		    
		<hr class="panel-cover__divider panel-cover__divider--secondary">
		<a href="#about">
			 <p class="panel-cover__description">About</p>
        </a>
		<br>
				<a href="#news">
				 <p class="panel-cover__description">News</p>
        </a>
    <br>
        <a href="#research">
         <p class="panel-cover__description">Research</p>
        </a>
		
		
		<hr class="panel-cover__divider panel-cover__divider--secondary">
		
        <div class="navigation-wrapper">

         <!--  <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="#blog" title="link to Deniz Engin blog" class="blog-button">Blog</a></li>
            </ul>
          </nav>
 -->
          <nav class="cover-navigation navigation--social">
            <ul class="navigation">
<!-- 
            
            
              <li class="navigation__item">
                <a href="http://twitter.com/Deniz.Engin_" title="@Deniz.Engin_ on Twitter" target="_blank">
                  <i class="icon icon-social-twitter"></i>
                  <span class="label">Twitter</span>
                </a>
              </li>
             -->

       
            
              <!-- LinkedIn -->
              <li class="navigation__item">
                <a href="https://www.linkedin.com/in/denizenginn" title="Deniz Engin on LinkedIn" target="_blank">
                  <i class="icon icon-social-linkedin"></i>
                  <span class="label">LinkedIn</span>
                </a>
              </li>
            

            
              <!-- GitHub -->
              <li class="navigation__item">
                <a href="https://www.github.com/engindeniz" title="Deniz Engin on GitHub" target="_blank">
                  <i class="icon icon-social-github"></i>
                  <span class="label">GitHub</span>
                </a>
              </li>
            

            
              <!-- Email -->
              <li class="navigation__item">
                <a href="mailto:deniz.engin@inria.fr" title="Email to Deniz Engin" target="_blank">
                  <i class="icon icon-mail"></i>
                  <span class="label">Email</span>
                </a>
              </li>
            

            <!-- RSS -->
            <!-- <li class="navigation__item">
              <a href="feed.xml" title="Subscribe" target="_blank">
                <i class="icon icon-rss"></i>
                <span class="label">RSS</span>
              </a>
            </li> -->

            </ul>
          </nav>

        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>


    <div class="content-wrapper">
      <div class="content-wrapper__inner">
        <!-- <div class="main-post-list">

  <ol class="post-list">
    
      <li>
        <h2 class="post-list__post-title post-title">
          Publications
          <a href="2016/01/08/welcome-to-jekyll.html" title="Publications"></a> 
        </h2>
        <p class="excerpt"><p>dhskdhsşasşahdşahfşahşahşhaaşohoaşoşahşfaşfaşYou’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve --watch</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<table>
  <tbody>
    <tr>
      <td><img src="images/cycle.png" alt="My dog" height="200px" width="300px" /></td>
      <td>To add new posts, simply add a file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory that follows the convention <code class="language-plaintext highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</td>
    </tr>
  </tbody>
</table>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span>
</code></pre></div></div>

<table>
  <tbody>
    <tr>
      <td>First</td>
      <td>Second</td>
    </tr>
  </tbody>
</table>

<p>Check out the <a href="http://jekyllrb.com">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://github.com/jekyll/jekyll-help">Jekyll’s dedicated Help repository</a>.</p>

&hellip;</p>
        <div class="post-list__meta">
            <time datetime="2016-01-08 00:00" class="post-list__meta--date date">8 Jan 2016</time>
            

        

        </div>
        <hr class="post-list__divider">
      </li>
    
  </ol>

  <hr class="post-list__divider ">

  

</div> -->


<div id="about" class="main-post-list">

  <ol class="post-list">
    
      <li>
        <h2 class="post-list__post-title post-title">
          About
          <!-- <a href="/Deniz.Engin" title=""></a> -->
        </h2>
        <p class="excerpt"><p>I am a PhD candidate at <a href="https://www-linkmedia.irisa.fr/">LinkMedia</a> team in <a href="https://www.inria.fr/fr/centre-inria-rennes-bretagne-atlantique">INRIA Rennes</a> and 
		<a href="https://www.interdigital.com/">InterDigital</a> working with <a href="https://avrithis.net/">Yannis Avrithis</a>, 
		<a href="https://www.interdigital.com/talent/?id=88">Ngoc Q. K. Duong</a>, <a href="https://sites.google.com/site/francoisschnitzler/">François Schnitzler</a>, and <a href="http://people.rennes.inria.fr/Teddy.Furon/website/Welcome.html">Teddy Furon</a>. 
		I have received my BS and MS degrees from Electronics Engineering at Istanbul Technical University. My research is focused on semantic multimodal question answering in videos.</p>

        <hr class="post-list__divider">
      </li>
    
  </ol>

  <hr class="post-list__divider ">

</div>



<div id="news" class="main-post-list">

  <ol class="post-list">
    
      <li>
        <h2 class="post-list__post-title post-title">
          News
          <!-- <a href="/Deniz.Engin" title=""></a> -->
        </h2>
        <p class="excerpt"><ul>
  <li>March 2021 - Preprint released at arXiv: <a href="https://arxiv.org/abs/2103.14517">On the Hidden Treasure of Dialog in Video Question Answering</a>.</li>
  <li>September 2020 - Starting my PhD at <a href="https://www.inria.fr/fr/centre-inria-rennes-bretagne-atlantique">INRIA Rennes</a> and <a href="https://www.interdigital.com/">InterDigital</a>.</li>
  <li>April 2020 - Our <a href="https://arxiv.org/abs/2004.12104">new paper</a> is accepted @<a href="https://vislab.ucr.edu/Biometrics2020/index.php">CVPR 2020 Biometrics Workshop</a>.</li>
  
</ul>
</p>

        <hr class="post-list__divider">
      </li>
    
  </ol>

  <hr class="post-list__divider ">

</div>


<h2  id="research"  class="post-list__post-title post-title">Research</h2>
<div class="main-post-list">

  <ol class="post-list">
    
      <li>
       <!--- <h2 class="post-list__post-title post-title">
          CVPRW2020
  <a href="/Deniz.Engin" title=""></a> 
        </h2> -->
        <p class="excerpt"><p>See <a href="http://scholar.google.com.tr/citations?user=5GQk5LUAAAAJ&amp;hl=tr">Google Scholar</a> for all publications.</p>

<div class="two-col-row">
<div>
<img src="images/signatureVerification.png" height="350px" width="350px" />
</div>
<div class="right-col">
 <a href="https://arxiv.org/abs/2004.12104">Offline Signature Verification on Real-World Documents</a>
  <br />
  <strong>Deniz Engin</strong>, Alperen Kantarcı, Seçil Arslan, Hazım Kemal Ekenel
  <br />
  <em>CVPR Biometrics Workshop, </em>2020<br />
<a href="https://arxiv.org/abs/2004.12104">arxiv</a> | <a class="abstract">abstract</a>
</div> </div>
</p>

        <div class="abstract" >
            <div style="width:50%">
            </div>
            <div class="right-col">  
              <p class="excerpt"> <p>Research on offline signature verification has explored a large variety of methods on multiple signature datasets, which are collected under controlled conditions. However, these datasets may not fully reflect the characteristics of the signatures in some practical use cases. Real-world signatures extracted from the formal documents may contain different types of occlusions, for example, stamps, company seals, ruling lines, and signature boxes. Moreover, they may have very high intra-class variations, where even genuine signatures resemble forgeries. In this paper, we address a real-world writer independent offline signature verification problem, in which, a bank’s customers’ transaction request documents that contain their occluded signatures are compared with their clean reference signatures. Our proposed method consists of two main components, a stamp cleaning method based on CycleGAN and signature representation based on CNNs. We extensively evaluate different verification setups, fine-tuning strategies, and signature representation approaches to have a thorough analysis of the problem. Moreover, we conduct a human evaluation to show the challenging nature of the problem. We run experiments both on our custom dataset, as well as on the publicly available Tobacco-800 dataset. The experimental results validate the difficulty of offline signature verification on real-world documents. However, by employing the stamp cleaning process, we improve the signature verification performance significantly.</p>
 </p>
            </div>
        </div>

      </li>
    
      <li>
       <!--- <h2 class="post-list__post-title post-title">
          CVPRW2018
  <a href="/Deniz.Engin" title=""></a> 
        </h2> -->
        <p class="excerpt"><div class="two-col-row">
<div><img src="images/cycle.png" height="200px" width="350px" /> </div>
<div class="right-col">
 <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Engin_Cycle-Dehaze_Enhanced_CycleGAN_CVPR_2018_paper.pdf">Cycle-Dehaze: Enhanced CycleGAN for Single Image Dehazing</a>
  <br />
  <strong>Deniz Engin</strong>, Anıl Genç, Hazım Kemal Ekenel
  <br />
  <em>CVPR NTIRE Workshop, </em>2018<br />
<a href="https://arxiv.org/abs/1805.05308">arxiv</a> |
<a href="https://github.com/Deniz.Enginniz/Cycle-Dehaze">code</a> | <a class="abstract">abstract</a>
</div>  </div>
</p>

        <div class="abstract" >
            <div style="width:50%">
            </div>
            <div class="right-col">  
              <p class="excerpt"> <p>In this paper, we present an end-to-end network, called Cycle-Dehaze, for single image dehazing problem, which does not require pairs of hazy and corresponding ground truth images for training. That is, we train the network by feeding clean and hazy images in an unpaired manner. Moreover, the proposed approach does not rely on estimation of the atmospheric scattering model parameters. Our method enhances CycleGAN formulation by combining cycle-consistency and perceptual losses in order to improve the quality of textural information recovery and generate visually better haze-free images. Typically, deep learning models for dehazing take low resolution images as input and produce low resolution outputs. However, in the NTIRE 2018 challenge on single image dehazing, high resolution images were provided. Therefore, we apply bicubic downscaling. After obtaining low-resolution outputs from the network, we utilize the Laplacian pyramid to upscale the output images to the original resolution. We conduct experiments on NYU-Depth, I-HAZE, and O-HAZE datasets. Extensive experiments demonstrate that the proposed approach improves CycleGAN method both quantitatively and qualitatively.</p>
 </p>
            </div>
        </div>

      </li>
    
      <li>
       <!--- <h2 class="post-list__post-title post-title">
          EUSIPCO2018
  <a href="/Deniz.Engin" title=""></a> 
        </h2> -->
        <p class="excerpt"><div class="two-col-row">
<div>
<img src="images/posenormalization.png" height="200px" width="350px" />
</div>
<div class="right-col">
<br /><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553087">Face Frontalization for Cross-Pose Facial Expression Recognition</a>
<br />
<strong>Deniz Engin</strong>, Christophe Ecabert, Hazım Kemal Ekenel, Jean-Philippe Thiran
<br />
<em>EUSIPCO, </em>2018<br />
<a class="abstract">abstract</a>
</div>
</div>
</p>

        <div class="abstract" >
            <div style="width:50%">
            </div>
            <div class="right-col">  
              <p class="excerpt"> <p>In this paper, we have explored the effect of pose normalization for cross-pose facial expression recognition. We have first presented an expression preserving face frontalization method. After face frontalization step, for facial expression representation and classification, we have employed both a traditional approach, by using hand-crafted features, namely local binary patterns, in combination with support vector machine classification and a relatively more recent approach based on convolutional neural networks. To evaluate the impact of face frontalization on facial expression recognition performance, we have conducted cross-pose, subject-independent expression recognition experiments using the BU3DFE database. Experimental results show that pose normalization improves the performance for cross-pose facial expression recognition. Especially, when local binary patterns in combination with support vector machine classifier is used, since this facial expression representation and classification does not handle pose variations, the obtained performance increase is significant. Convolutional neural networks-based approach is found to be more successful handling pose variations, when it is fine-tuned on a dataset that contains face images with varying pose angles. Its performance is further enhanced by benefiting from face frontalization.</p>
 </p>
            </div>
        </div>

      </li>
    
  </ol>


</div>


      </div>

      <footer class="footer" id="footer">
  <span class="footer__copyright"> &copy; Deniz Engin | Last Update:2021 </span>
</footer>

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script type="text/javascript" src="js/main.js?1589893399693513343"></script>


    </div>
  </body>
</html>